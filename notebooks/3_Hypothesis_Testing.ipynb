{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97754e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Her\\AppData\\Local\\Temp\\ipykernel_35860\\124543369.py:9: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/MachineLearningRating_v3.txt', sep='|') # or the .csv if you saved a clean version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and columns cleaned.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats  # Required for T-tests, Chi-Squared, ANOVA\n",
    "\n",
    "# Load your cleaned data (ensure path is correct relative to the notebooks folder)\n",
    "try:\n",
    "    df = pd.read_csv('../data/MachineLearningRating_v3.txt', sep='|') # or the .csv if you saved a clean version\n",
    "    \n",
    "    # Quick fix for column names just in case\n",
    "    df.columns = df.columns.str.strip().str.replace('[^A-Za-z0-9_]+', '_', regex=True).str.lower()\n",
    "    \n",
    "    print(\"Data loaded and columns cleaned.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Check your path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fcea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete. Financial columns converted to numeric.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Address DtypeWarning and Final Cleaning ---\n",
    "\n",
    "# Re-load the data and explicitly set low_memory=False to let pandas determine types better\n",
    "# We keep the column cleanup just in case.\n",
    "file_path = '../data/MachineLearningRating_v3.txt'\n",
    "df = pd.read_csv(file_path, sep='|', low_memory=False)\n",
    "\n",
    "# Re-apply the column cleanup\n",
    "df.columns = df.columns.str.strip().str.replace('[^A-Za-z0-9_]+', '_', regex=True).str.lower()\n",
    "\n",
    "# Columns 32 and 37 are likely 'calculatedpremiumperterm' and 'suminsured'\n",
    "# We will coerce all critical financial columns to numeric, converting errors to NaN\n",
    "financial_cols = ['totalpremium', 'totalclaims', 'customvalueestimate', 'calculatedpremiumperterm', 'suminsured']\n",
    "\n",
    "for col in financial_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Drop any rows that became entirely invalid (optional, but good practice)\n",
    "df.dropna(subset=financial_cols, inplace=True)\n",
    "\n",
    "print(\"Data cleaning complete. Financial columns converted to numeric.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347c187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KPIs Created:\n",
      "                 count       mean            min            max\n",
      "totalpremium  220456.0  74.813039     -80.409357    1538.957719\n",
      "totalclaims   220456.0  74.989311       0.000000  363343.421053\n",
      "claimed       220456.0   0.002989       0.000000       1.000000\n",
      "margin        220456.0  -0.176272 -362278.393070    1538.957719\n",
      "\n",
      "Total Policies (df): 220456\n",
      "Policies with Claims (df_severity): 659\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Create the Required KPIs ---\n",
    "\n",
    "# 1. Claim Frequency (The 'claimed' binary column)\n",
    "# If totalclaims > 0, set to 1. Otherwise, set to 0.\n",
    "df['claimed'] = np.where(df['totalclaims'] > 0, 1, 0)\n",
    "\n",
    "# 2. Margin (Profit Calculation)\n",
    "# Margin = TotalPremium - TotalClaims\n",
    "df['margin'] = df['totalpremium'] - df['totalclaims']\n",
    "\n",
    "# 3. Prepare Data for Claim Severity\n",
    "# Create the subset of data for testing severity hypotheses.\n",
    "df_severity = df[df['claimed'] == 1].copy()\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"\\nKPIs Created:\")\n",
    "print(df[['totalpremium', 'totalclaims', 'claimed', 'margin']].describe().T[['count', 'mean', 'min', 'max']])\n",
    "print(f\"\\nTotal Policies (df): {len(df)}\")\n",
    "print(f\"Policies with Claims (df_severity): {len(df_severity)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f167179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Claim Frequency (Gender) ---\n",
      "Observed Frequencies:\n",
      "claimed             0    1\n",
      "gender                    \n",
      "Female            115    1\n",
      "Male             3997   12\n",
      "Not specified  213651  642\n",
      "Chi-Squared Statistic: 1.2269\n",
      "P-Value: 0.5415\n"
     ]
    }
   ],
   "source": [
    "# Create the contingency table: Gender vs. Claimed (0 or 1)\n",
    "contingency_table = df.groupby(['gender', 'claimed']).size().unstack(fill_value=0)\n",
    "\n",
    "# Ensure both 0 (Not Claimed) and 1 (Claimed) columns exist, though they usually will\n",
    "if 1 not in contingency_table.columns:\n",
    "    contingency_table[1] = 0\n",
    "if 0 not in contingency_table.columns:\n",
    "    contingency_table[0] = 0\n",
    "\n",
    "# Select only the Claimed column for the test (Optional: Can use the whole table for chi2)\n",
    "# We use the full table for the standard Chi-Squared test\n",
    "chi2, p_value_freq, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "print(\"--- Claim Frequency (Gender) ---\")\n",
    "print(f\"Observed Frequencies:\\n{contingency_table}\")\n",
    "print(f\"Chi-Squared Statistic: {chi2:.4f}\")\n",
    "print(f\"P-Value: {p_value_freq:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9688626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Claim Severity (Gender) ---\n",
      "Men Average Claim: nan\n",
      "Women Average Claim: nan\n",
      "T-Statistic: nan\n",
      "P-Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Her\\Desktop\\Week-3\\.venv\\Lib\\site-packages\\scipy\\_lib\\deprecation.py:234: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Filter severity data into two groups: Women and Men\n",
    "men_claims = df_severity[df_severity['gender'] == 'men']['totalclaims']\n",
    "women_claims = df_severity[df_severity['gender'] == 'women']['totalclaims']\n",
    "\n",
    "# Perform the independent two-sample t-test (assuming unequal variance, which is safe)\n",
    "t_stat_severity, p_value_severity = stats.ttest_ind(\n",
    "    men_claims, \n",
    "    women_claims, \n",
    "    equal_var=False # Assumes variances are not equal\n",
    ")\n",
    "\n",
    "print(\"\\n--- Claim Severity (Gender) ---\")\n",
    "print(f\"Men Average Claim: {men_claims.mean():.2f}\")\n",
    "print(f\"Women Average Claim: {women_claims.mean():.2f}\")\n",
    "print(f\"T-Statistic: {t_stat_severity:.4f}\")\n",
    "print(f\"P-Value: {p_value_severity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d993f801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Claim Frequency (Province) ---\n",
      "Chi-Squared Statistic: 26.5474\n",
      "P-Value: 0.0008\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Claim Frequency across all Provinces (Chi-Squared) ---\n",
    "# Assuming your province column is named 'province'\n",
    "\n",
    "# Create contingency table: Province vs. Claimed (0 or 1)\n",
    "province_freq_table = df.groupby(['province', 'claimed']).size().unstack(fill_value=0)\n",
    "\n",
    "chi2_province_freq, p_value_province_freq, dof_province_freq, expected_province_freq = stats.chi2_contingency(province_freq_table)\n",
    "\n",
    "print(\"\\n--- Claim Frequency (Province) ---\")\n",
    "print(f\"Chi-Squared Statistic: {chi2_province_freq:.4f}\")\n",
    "print(f\"P-Value: {p_value_province_freq:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d4054e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Claim Severity (Province) ---\n",
      "F-Statistic: 1.4913\n",
      "P-Value: 0.1568\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Claim Severity across all Provinces (ANOVA) ---\n",
    "# Requires filtering the severity data by province\n",
    "\n",
    "# Identify all provinces in the severity subset\n",
    "province_groups = [\n",
    "    df_severity[df_severity['province'] == prov]['totalclaims']\n",
    "    for prov in df_severity['province'].unique()\n",
    "]\n",
    "\n",
    "# Run ANOVA test to compare the means of totalclaims across all provinces\n",
    "f_stat_province_severity, p_value_province_severity = stats.f_oneway(*province_groups)\n",
    "\n",
    "print(\"\\n--- Claim Severity (Province) ---\")\n",
    "print(f\"F-Statistic: {f_stat_province_severity:.4f}\")\n",
    "print(f\"P-Value: {p_value_province_severity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e61b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ZIP CODE HYPOTHESIS TEST PREP ---\n",
    "\n",
    "# 1. Filter to high volume zip codes (Adjust threshold as needed, e.g., 50)\n",
    "ZIP_THRESHOLD = 50\n",
    "zip_counts = df['postalcode'].value_counts()\n",
    "high_volume_zips = zip_counts[zip_counts >= ZIP_THRESHOLD].index\n",
    "\n",
    "df_filtered = df[df['postalcode'].isin(high_volume_zips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbecf3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Identify High Risk and Low Risk Groups based on your EDA (use mean Claimed or mean Margin)\n",
    "zip_summary = df_filtered.groupby('postalcode').agg(\n",
    "    ClaimRate=('claimed', 'mean'),\n",
    "    AvgMargin=('margin', 'mean')\n",
    ").sort_values(by='ClaimRate', ascending=False)\n",
    "\n",
    "# Select the top and bottom 10 for comparison\n",
    "top_risky_zips = zip_summary.head(10).index\n",
    "low_risky_zips = zip_summary.tail(10).index\n",
    "\n",
    "# Create test groups\n",
    "high_risk_group = df_filtered[df_filtered['postalcode'].isin(top_risky_zips)]\n",
    "low_risk_group = df_filtered[df_filtered['postalcode'].isin(low_risky_zips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e768e0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Claim Severity (Zip Code - T-Test High vs. Low) ---\n",
      "P-Value: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Her\\Desktop\\Week-3\\.venv\\Lib\\site-packages\\scipy\\_lib\\deprecation.py:234: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Hypothesis 2: Claim Severity (Risk Difference) ---\n",
    "# Filter to policies with claims in the high/low risk groups for severity testing\n",
    "high_risk_severity = high_risk_group[high_risk_group['claimed'] == 1]['totalclaims']\n",
    "low_risk_severity = low_risk_group[low_risk_group['claimed'] == 1]['totalclaims']\n",
    "\n",
    "t_stat_zip_severity, p_value_zip_severity = stats.ttest_ind(\n",
    "    high_risk_severity, \n",
    "    low_risk_severity, \n",
    "    equal_var=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- Claim Severity (Zip Code - T-Test High vs. Low) ---\")\n",
    "print(f\"P-Value: {p_value_zip_severity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78516ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Margin Difference (Zip Code - T-Test High vs. Low) ---\n",
      "P-Value: 0.0034\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Hypothesis 3: Margin (Profit Difference) ---\n",
    "\n",
    "# Compare the average margin between the two groups\n",
    "t_stat_zip_margin, p_value_zip_margin = stats.ttest_ind(\n",
    "    high_risk_group['margin'], \n",
    "    low_risk_group['margin'], \n",
    "    equal_var=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- Margin Difference (Zip Code - T-Test High vs. Low) ---\")\n",
    "print(f\"P-Value: {p_value_zip_margin:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72696650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Claim Severity (Zip Code - Revised T-Test High vs. All Others) ---\n",
      "P-Value: 0.8054\n"
     ]
    }
   ],
   "source": [
    "# --- ZIP CODE HYPOTHESIS 2 (Severity) - REVISED T-TEST ---\n",
    "\n",
    "# Group 1: High Risk Zip Codes (already defined)\n",
    "high_risk_severity = high_risk_group[high_risk_group['claimed'] == 1]['totalclaims']\n",
    "\n",
    "# Group 2: The rest of the policies with claims (Control Group)\n",
    "# Filter main DF to claims, then exclude the high_risk_zips\n",
    "df_severity_control = df_severity[~df_severity['postalcode'].isin(top_risky_zips)]\n",
    "control_severity = df_severity_control['totalclaims']\n",
    "\n",
    "# Run the T-test again\n",
    "t_stat_zip_severity_revised, p_value_zip_severity_revised = stats.ttest_ind(\n",
    "    high_risk_severity, \n",
    "    control_severity, \n",
    "    equal_var=False \n",
    ")\n",
    "\n",
    "print(\"\\n--- Claim Severity (Zip Code - Revised T-Test High vs. All Others) ---\")\n",
    "print(f\"P-Value: {p_value_zip_severity_revised:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55dd5001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Claim Severity (Gender - Revised T-Test Men vs. Others) ---\n",
      "P-Value: nan\n"
     ]
    }
   ],
   "source": [
    "# --- GENDER HYPOTHESIS 4 (Severity) - REVISED T-TEST ---\n",
    "\n",
    "# Check which group is larger (likely Men) and compare it against the rest.\n",
    "# Let's compare Men vs. Women + Not Specified claims.\n",
    "\n",
    "men_claims = df_severity[df_severity['gender'] == 'men']['totalclaims']\n",
    "non_men_claims = df_severity[df_severity['gender'] != 'men']['totalclaims']\n",
    "\n",
    "# Run the independent two-sample t-test \n",
    "t_stat_gender_severity_revised, p_value_gender_severity_revised = stats.ttest_ind(\n",
    "    men_claims, \n",
    "    non_men_claims, \n",
    "    equal_var=False\n",
    ")\n",
    "\n",
    "print(\"\\n--- Claim Severity (Gender - Revised T-Test Men vs. Others) ---\")\n",
    "print(f\"P-Value: {p_value_gender_severity_revised:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73440da8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
